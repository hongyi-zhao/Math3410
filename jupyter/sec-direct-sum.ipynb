{
"cells": [
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":["%%html\n<link href=\"https:\/\/pretextbook.org\/beta\/mathbook-content.css\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/aimath.org\/mathbook\/mathbook-add-on.css\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/fonts.googleapis.com\/css?family=Open+Sans:400,400italic,600,600italic\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/fonts.googleapis.com\/css?family=Inconsolata:400,700&subset=latin,latin-ext\" rel=\"stylesheet\" type=\"text\/css\" \/><!-- Hide this cell. -->\n<script>\nvar cell = $(\".container .cell\").eq(0), ia = cell.find(\".input_area\")\nif (cell.find(\".toggle-button\").length == 0) {\nia.after(\n    $('<button class=\"toggle-button\">Toggle hidden code<\/button>').click(\n        function (){ ia.toggle() }\n        )\n    )\nia.hide()\n}\n<\/script>\n"], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["**Important:** to view this notebook properly you will need to execute the cell above, which assumes you have an Internet connection.  It should already be selected, or place your cursor anywhere above to select.  Then press the \"Run\" button in the menu bar above (the right-pointing arrowhead), or press Shift-Enter on your keyboard."]},
{"cell_type":"markdown", "metadata":{}, "source":["$\\newcommand{\\spn}{\\operatorname{span}}\n\\newcommand{\\bbm}{\\begin{bmatrix}}\n\\newcommand{\\ebm}{\\end{bmatrix}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\renewcommand{\\C}{\\mathbb{C}}\n\\newcommand{\\im}{\\operatorname{im}}\n\\newcommand{\\nll}{\\operatorname{null}}\n\\newcommand{\\csp}{\\operatorname{col}}\n\\newcommand{\\rank}{\\operatorname{rank}}\n\\newcommand{\\diag}{\\operatorname{diag}}\n\\newcommand{\\tr}{\\operatorname{tr}}\n\\newcommand{\\dotp}{\\!\\boldsymbol{\\cdot}\\!}\n\\newcommand{\\len}[1]{\\lVert #1\\rVert}\n\\newcommand{\\abs}[1]{\\lvert #1\\rvert}\n\\newcommand{\\proj}[2]{\\operatorname{proj}_{#1}{#2}}\n\\newcommand{\\bz}{\\overline{z}}\n\\newcommand{\\zz}{\\mathbf{z}}\n\\newcommand{\\uu}{\\mathbf{u}}\n\\newcommand{\\vv}{\\mathbf{v}}\n\\newcommand{\\ww}{\\mathbf{w}}\n\\newcommand{\\xx}{\\mathbf{x}}\n\\newcommand{\\yy}{\\mathbf{y}}\n\\newcommand{\\zer}{\\mathbf{0}}\n\\newcommand{\\basis}[2]{\\{\\mathbf{#1}_1,\\mathbf{#1}_2,\\ldots,\\mathbf{#1}_{#2}\\}}\n\\newcommand{\\lt}{<}\n\\newcommand{\\gt}{>}\n\\newcommand{\\amp}{&}\n$"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h6 class=\"heading hide-type\"><span xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"type\">Section<\/span> <span class=\"codenumber\">5.3<\/span> <span class=\"title\">Direct Sums and Invariant Subspaces<\/span><\/h6><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-656\">Much of this section has been mentioned previously in the course (and these notes), but we will follow the organization of Nicholson's textbook, and reprise these concepts in more detail than previously.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h6 class=\"heading hide-type\"><span xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"type\">Subsection<\/span> <span class=\"codenumber\">5.3.1<\/span> <span class=\"title\">Invariant subspaces<\/span><\/h6><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"definition definition-like\" id=\"def-invariant-subspace\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Definition<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">5.3.1<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-657\">Given an operator $T:V\\to V\\text{,}$ we say that a subspace $U\\subseteq V$ is $T$-<dfn class=\"terminology\">invariant<\/dfn> if $T(\\uu)\\in U$ for all $\\uu\\in U\\text{.}$<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-658\">In other words, a subspace $U$ is $T$-invariant if $T$ does not map any vectors in $U$ outside of $U\\text{.}$ Notice that if we shrink the domain of $T$ to $U\\text{,}$ then we get an operator from $U$ to $U\\text{,}$ since the image $T(U)$ is contained in $U\\text{.}$<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-659\">Given a basis $B=\\basis{u}{k}$ of $U\\text{,}$ note that $U$ is $T$-invariant if and only if $T(\\uu_i)\\in U$ for each $i=1,2,\\ldots, k\\text{.}$<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-660\">For any operator $T:V\\to V\\text{,}$ there are four subspaces that are always $T$-invariant:<\/p><div xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"displaymath\">\n\\begin{equation*}\n\\{\\mathbf{0}\\}, V, \\ker T, \\text{ and } \\im T\\text{.}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">Of course, some of these subspaces might be the same; for example, if $T$ is invertible, then $\\ker T = \\{\\mathbf{0}\\}$ and $\\im T = V\\text{.}$ (We will skip the proof that $\\ker T$ and $\\im T$ are $T$-invariant, since this has been assigned as homework!)<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"definition definition-like\" id=\"def-restriction\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Definition<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">5.3.2<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-661\">Let $T:V\\to V$ be a linear operator, and let $U$ be a $T$-invariant subspace. The <dfn class=\"terminology\">restriction<\/dfn> of $T$ to $U\\text{,}$ denoted $T|_U\\text{,}$ is the operator $T|_U:U\\to U$ defined by $T|_U(\\uu)=T(\\uu)$ for all $\\uu\\in U\\text{.}$<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-662\">Notice that the restriction $T|_U$ is defined by the same “rule” as $T\\text{,}$ but its domain is the subspace $U$ instead of the entire vector space $V\\text{.}$<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-663\">A lot can be learned by studying the restrictions of an operator to invariant subspaces. Indeed, the textbook by Axler does almost everything from this point of view. One reason to study invariant subspaces is that they allow us to put the matrix of $T$ into simpler forms.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem theorem-like\" id=\"thm-invariant-block-triangular\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Theorem<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">5.3.3<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-664\">Let $T:V\\to V$ be a linear operator, and let $U$ be a $T$-invariant subspace. Let $B_U = \\basis{u}{k}$ be a basis of $U\\text{,}$ and extend this to a basis<\/p><div class=\"displaymath\">\n\\begin{equation*}\nB = \\{\\uu_1,\\ldots, \\uu_k,\\ww_1,\\ldots, \\ww_{n-k}\\}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">of $V\\text{.}$ Then the matrix $M_B(T)$ with respect to this basis has the block-triangular form<\/p><div class=\"displaymath\">\n\\begin{equation*}\nM_B(T) = \\bbm M_{B_U}(T_U) \\amp P\\\\0 \\amp Q\\ebm\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">for some $(n-k)\\times (n-k)$ matrix $Z\\text{.}$<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-665\">Reducing a matrix to block triangular form is useful, because it simplifies computations such as determinants and eigenvalues (and determinants and eigenvalues are computationally expensive). In particular, if a matrix $A$ has the block form<\/p><div xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"displaymath\">\n\\begin{equation*}\nA = \\bbm A_{11} \\amp A_{12} \\amp \\cdots A_{1n}\\\\\n0\\amp A_{22} \\amp \\cdots A_{2n}\\\\\n\\vdots \\amp \\vdots \\amp \\ddots \\amp \\vdots\\\\\n0 \\amp 0 \\amp \\cdots \\amp A_{nn}\\ebm\\text{,}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">where the diagonal blocks are square matrices, then $\\det(A) = \\det(A_{11})\\det(A_{22})\\cdots \\det(A_{nn})$ and $c_A(x) = c_{A_{11}}(x)c_{A_{22}}(x)\\cdots C_{A_{nn}}(x)\\text{.}$<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h6 class=\"heading hide-type\"><span xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"type\">Subsection<\/span> <span class=\"codenumber\">5.3.2<\/span> <span class=\"title\">Eigenspaces<\/span><\/h6><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-666\">An important source of invariant subspaces is eigenspaces. Recall that for any real number $\\lambda\\text{,}$ and any operator $T:V\\to V\\text{,}$ we define<\/p><div xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"displaymath\">\n\\begin{equation*}\nE_\\lambda(T) = \\ker(T-\\lambda 1_V) = \\{\\vv\\in V \\,|\\, T(\\vv) = \\lambda\\vv\\}\\text{.}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">For most values of $\\lambda\\text{,}$ we'll have $E_\\lambda(T)=\\{\\mathbf{0}\\}\\text{.}$ The values of $\\lambda$ for which $E_\\lambda(T)$ is non-trivial are precisely the eigenvalues of $T\\text{.}$ Note that since similar matrices have the same characteristic polynomial any matrix representation $M_B(T)$ will have the same eigenvalues. They do <em class=\"emphasis\">not<\/em> generally have the same eigenspaces, but we do have the following.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem theorem-like\" id=\"thm-eigenspace-invariant\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Theorem<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">5.3.4<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-667\">Let $T:V\\to V$ be a linear operator. For any scalar $\\lambda\\text{,}$ the eigenspace $E_\\lambda(T)$ is $T$-invariant. Moreover, for any ordered basis $B$ of $V\\text{,}$ the coefficient isomorphism $C_B:V\\to \\R^n$ induces an isomorphism<\/p><div class=\"displaymath\">\n\\begin{equation*}\nC_B|_{E_\\lambda(T)}:E_\\lambda(T)\\to E_{\\lambda}(M_B(T))\\text{.}\n\\end{equation*}\n<\/div><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h6 class=\"heading hide-type\"><span xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"type\">Subsection<\/span> <span class=\"codenumber\">5.3.3<\/span> <span class=\"title\">Direct Sums<\/span><\/h6><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-668\">Recall that for any subspaces $U,W$ of a vector space $V\\text{,}$ the sets<\/p><div xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"displaymath\">\n\\begin{align*}\nU+W \\amp =\\{\\uu+\\ww \\,|\\, \\uu\\in U \\text{ and } \\ww\\in W\\}\\\\\nU\\cap W \\amp = \\{\\vv \\in V \\,|\\, \\vv\\in U \\text{ and } \\vv\\in W\\}\n\\end{align*}\n<\/div><p data-braille=\"continuation\">are subspaces of $V\\text{.}$ Saying that $\\vv\\in U+W$ means that $\\vv$ can be written as a sum of a vector in $U$ and a vector in $W\\text{.}$ However, this sum may not be unique. If $\\vv\\in U\\cap W\\text{,}$ $\\uu\\in U$ and $\\ww\\in W\\text{,}$ then we can write $(\\uu+\\vv)+\\ww = \\uu + (\\vv+\\ww)\\text{,}$ giving two different representations of a vector as an element of $U+W\\text{.}$<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem theorem-like\" id=\"thm-unique-sum\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Theorem<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">5.3.5<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-669\">Let $U$ and $W$ be subspaces of a vector space $V\\text{.}$ Let $\\vv\\in U+W\\text{.}$ Then there exist <em class=\"emphasis\">unique<\/em> vectors $\\uu\\in U, \\ww\\in W$ such that $\\vv = \\uu+\\ww$ if and only if $U\\cap W = \\{\\mathbf{0}\\}\\text{.}$<\/p><\/article><article class=\"proof\" id=\"proof-26\"><h6 class=\"heading\"><span class=\"type\">Proof<span class=\"period\">.<\/span><\/span><\/h6><p id=\"p-670\">Suppose $U+W$ has the property that if $\\vv\\in U+W\\text{,}$ then there exist unique $\\uu\\in U,\\ww\\in W$ such that $\\vv=\\uu+\\ww\\text{.}$ Suppose $\\mathbf{x}\\in U\\cap W\\text{.}$ Then $\\xx\\in U$ and $\\xx\\in W\\text{,}$ which implies that $-\\xx\\in W\\text{,}$ since $W$ is a subspace. Then we can write<\/p><div class=\"displaymath\">\n\\begin{equation*}\n\\mathbf{0} = \\xx + (-\\xx)\\text{,}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">with $\\xx\\in U$ and $-\\xx\\in W\\text{.}$ But we also know that $\\mathbf{0}\\in U$ and $\\mathbf{0}\\in W\\text{,}$ so we can also write $\\mathbf{0}=\\mathbf{0}+\\mathbf{0}\\text{.}$ Since we can only write $\\mathbf{0}$ in one way as a sum of a vector in $U$ and a vector in $W\\text{,}$ we must have $\\xx=\\mathbf{0}\\text{,}$ showing that $U\\cap W = \\{\\mathbf{0}\\}\\text{.}$<\/p><p id=\"p-671\">Conversely, suppose that $U\\cap W = \\{\\zer\\}\\text{,}$ and let $\\vv\\in U+W\\text{.}$ Suppose that there exist vectors $\\uu_1,\\uu_2\\in U$ and $\\ww_1,\\ww_2\\in W$ such that $\\vv = \\uu_1+\\ww_1=\\uu_2+\\ww_2\\text{.}$ But then $\\uu_1-\\uu_2=\\ww_2-\\ww_1\\text{,}$ and since $\\uu_1-\\uu_2\\in U$ and $\\ww_2-\\ww_1\\in W\\text{,}$ we have $\\uu_1-\\uu_2=\\ww_2-\\ww_1\\in U\\cap W\\text{.}$ Since $U\\cap W=\\{\\zer\\}\\text{,}$ we have $\\uu_1-\\uu_2=\\zer$ and $\\ww_2-\\ww_1=\\zer\\text{,}$ so $\\uu_1=\\uu_2$ and $\\ww_1=\\ww_2\\text{.}$<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"definition definition-like\" id=\"def-direct-sum\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Definition<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">5.3.6<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-672\">We say that a sum $U+W$ is a <dfn class=\"terminology\">direct sum<\/dfn>, and write this sum as $U\\oplus W\\text{,}$ if $U\\cap W = \\{\\mathbf{0}\\}\\text{.}$<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-673\">Typically we are interested in the case that the two subspaces sum to $V\\text{.}$ If $V = U\\oplus W\\text{,}$ we say that $W$ is a <dfn class=\"terminology\">complement<\/dfn> of $U\\text{,}$ and that $U\\oplus W$ is a direct sum decomposition of $V\\text{.}$ Of course, the orthogonal complement $U^\\bot$ of a subspace $U$ is a complement in this sense, if $V$ is equipped with an inner product. (Without an inner product we have no concept of “orthogonal”.) But even if we don't have an inner product, finding a complement is not too difficult, as the next example shows.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example example-like\" id=\"eg-direct-sum-basis\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Example<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">5.3.7<\/span><span class=\"period\">.<\/span><span class=\"space\"> <\/span><span class=\"title\">Finding a complement by extending a basis.<\/span><\/h6><p id=\"p-674\">The easiest way to determine a direct sum decomposition (or equivalently, a complement) is through the use of a basis. Suppose $U$ is a subspace of $V$ with basis $\\basis{e}{k}\\text{,}$ and extend this to a basis<\/p><div class=\"displaymath\">\n\\begin{equation*}\nB = \\{\\mathbf{e}_1,\\ldots, \\mathbf{e}_k,\\mathbf{e}_{k+1},\\ldots, \\mathbf{e}_n\\}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">of $V\\text{.}$ Let $W = \\spn\\{\\mathbf{e}_{k+1},\\ldots, \\mathbf{e}_n\\}\\text{.}$ Then clearly $U+W=V\\text{,}$ and $U\\cap W=\\{\\zer\\}\\text{,}$ since if $\\vv\\in U\\cap W\\text{,}$ then $\\vv\\in U$ and $\\vv\\in W\\text{,}$ so we have<\/p><div class=\"displaymath\">\n\\begin{equation*}\n\\vv = a_1\\mathbf{e}_1+\\cdots + a_k\\mathbf{e_k} = b_1\\mathbf{e}_{k+1}+\\cdots+b_{n-k}e_{n}\\text{,}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">which gives<\/p><div class=\"displaymath\">\n\\begin{equation*}\na_1\\mathbf{e}_1+\\cdots + a_k\\mathbf{e}_k-b_1\\mathbf{e}_{k+1}-\\cdots - b_{n-k}\\mathbf{e}_n=\\zer\\text{,}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">so $a_1=\\cdots b_{n-k}=0$ by the linear independence of $B\\text{,}$ showing that $\\vv=\\zer\\text{.}$<\/p><p id=\"p-675\">Conversely, if $V=U\\oplus W\\text{,}$ and we have bases $\\basis{u}{k}$ of $U$ and $\\basis{v}{l}$ of $W\\text{,}$ then<\/p><div class=\"displaymath\">\n\\begin{equation*}\nB = \\{\\uu_1,\\ldots, \\uu_k,\\ww_1,\\ldots, \\ww_l\\}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">is a basis for $V\\text{.}$ Indeed, $B$ spans $V\\text{,}$ since every element of $V$ can be written as $\\vv=\\uu+\\ww$ with $\\uu\\in U,\\ww\\in W\\text{.}$ Independence follows by reversing the argument above: if<\/p><div class=\"displaymath\">\n\\begin{equation*}\na_1\\uu_1+\\cdots + a_k\\uu_k+b_1\\ww_1+\\cdots b_l\\ww_l=\\zer\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">then $a_1\\uu_1+\\cdots + a_k\\uu_k = -b_1\\ww_1-\\cdots -b_l\\ww_l\\text{,}$ and equality is only possible if both sides belong to $U\\cap W = \\{\\zer\\}\\text{.}$ Since $\\basis{u}{k}$ is independent, the $a_i$ have to be zero, and since $\\basis{w}{l}$ is independent, the $b_j$ have to be zero.<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-676\">The argument given in the second part of <a href=\"sec-direct-sum.ipynb#eg-direct-sum-basis\" class=\"internal\" title=\"Example 5.3.7: Finding a complement by extending a basis\">Example 5.3.7<\/a> has an immediate, but important consequence.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem theorem-like\" id=\"thm-direct-sum-dimension\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Theorem<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">5.3.8<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-677\">Suppose $V=U\\oplus W\\text{,}$ where $\\dim U = m$ and $\\dim W = n\\text{.}$ Then $V$ is finite-dimensional, and $\\dim V = m+n\\text{.}$<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example example-like\" id=\"eg-invariant-block\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Example<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">5.3.9<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-678\">Suppose $V=U\\oplus W\\text{,}$ where $U$ and $W$ are $T$-invariant subspaces for some operator $T:V\\to V\\text{.}$ Let $B_U=\\basis{u}{m}$ and let $B_W = \\basis{w}{n}$ be bases for $U$ and $W\\text{,}$ respectively. Determine the matrix of $T$ with respect to the basis $B=B_U\\cup B_W$ of $V\\text{.}$<\/p><div class=\"solutions\"><a data-knowl=\"\" class=\"id-ref solution-knowl original\" data-refid=\"hk-solution-42\" id=\"solution-42\"><span class=\"type\">Solution<\/span><\/a><div class=\"hidden-content tex2jax_ignore\" id=\"hk-solution-42\"><div class=\"solution solution-like\"><p id=\"p-679\">Since we don't know the map $T$ or anything about the bases $B_U,B_W\\text{,}$ we're looking for a fairly general statement here. Since $U$ is $T$-invariant, we must have $T(\\uu_i)\\in U$ for each $i=1,\\ldots, m\\text{.}$ Similarly, $T(\\ww_j)\\in W$ for each $j=1,\\ldots, n\\text{.}$ This means that we have<\/p><div class=\"displaymath\">\n\\begin{align*}\nT(\\uu_1) \\amp = a_{11}\\uu_1 + \\cdots + a_{m1}\\uu_m + 0\\ww_1+\\cdots + 0\\ww_n\\\\\n\\amp \\vdots \\\\\nT(\\uu_m) \\amp = a_{1m}\\uu_1 + \\cdots + a_{mm}\\uu_m+0\\ww_1+\\cdots + 0\\ww_n\\\\\nT(\\ww_1) \\amp = 0\\uu_1 + \\cdots + 0\\uu_m+b_{11}\\ww_1 + \\cdots + b_{n1}\\ww_n \\\\\n\\amp \\vdots \\\\\nT(\\ww_n) \\amp = 0\\uu_1 + \\cdots + 0\\uu_m+b_{1n}\\ww_1 + \\cdots + b_{nn}\\ww_n\n\\end{align*}\n<\/div><p data-braille=\"continuation\">for some scalars $a_{ij},b_{ij}\\text{.}$ If we set $A = [a_{ij}]_{m\\times m}$ and $B = [b_{ij}]_{n\\times n}\\text{,}$ then we have<\/p><div class=\"displaymath\">\n\\begin{equation*}\nM_B(T) = \\bbm A \\amp 0\\\\0\\amp B\\ebm\\text{.}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">Moreover, we can also see that $A = M_{B_U}(T|_U)\\text{,}$ and $B = M_{B_W}(T|_W)\\text{.}$<\/p><\/div><\/div><\/div><\/article><\/div>"]}
],
"nbformat": 4, "nbformat_minor": 0, "metadata": {"kernelspec": {"display_name": "", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}, "name": "sec-direct-sum.ipynb"}
}