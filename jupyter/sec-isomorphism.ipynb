{
"cells": [
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":["%%html\n<link href=\"https:\/\/pretextbook.org\/beta\/mathbook-content.css\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/aimath.org\/mathbook\/mathbook-add-on.css\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/fonts.googleapis.com\/css?family=Open+Sans:400,400italic,600,600italic\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/fonts.googleapis.com\/css?family=Inconsolata:400,700&subset=latin,latin-ext\" rel=\"stylesheet\" type=\"text\/css\" \/><!-- Hide this cell. -->\n<script>\nvar cell = $(\".container .cell\").eq(0), ia = cell.find(\".input_area\")\nif (cell.find(\".toggle-button\").length == 0) {\nia.after(\n    $('<button class=\"toggle-button\">Toggle hidden code<\/button>').click(\n        function (){ ia.toggle() }\n        )\n    )\nia.hide()\n}\n<\/script>\n"], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["**Important:** to view this notebook properly you will need to execute the cell above, which assumes you have an Internet connection.  It should already be selected, or place your cursor anywhere above to select.  Then press the \"Run\" button in the menu bar above (the right-pointing arrowhead), or press Shift-Enter on your keyboard."]},
{"cell_type":"markdown", "metadata":{}, "source":["$\\newcommand{\\spn}{\\operatorname{span}}\n\\newcommand{\\bbm}{\\begin{bmatrix}}\n\\newcommand{\\ebm}{\\end{bmatrix}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\renewcommand{\\C}{\\mathbb{C}}\n\\newcommand{\\im}{\\operatorname{im}}\n\\newcommand{\\nll}{\\operatorname{null}}\n\\newcommand{\\csp}{\\operatorname{col}}\n\\newcommand{\\rank}{\\operatorname{rank}}\n\\newcommand{\\diag}{\\operatorname{diag}}\n\\newcommand{\\tr}{\\operatorname{tr}}\n\\newcommand{\\dotp}{\\!\\boldsymbol{\\cdot}\\!}\n\\newcommand{\\len}[1]{\\lVert #1\\rVert}\n\\newcommand{\\abs}[1]{\\lvert #1\\rvert}\n\\newcommand{\\proj}[2]{\\operatorname{proj}_{#1}{#2}}\n\\newcommand{\\bz}{\\overline{z}}\n\\newcommand{\\zz}{\\mathbf{z}}\n\\newcommand{\\uu}{\\mathbf{u}}\n\\newcommand{\\vv}{\\mathbf{v}}\n\\newcommand{\\ww}{\\mathbf{w}}\n\\newcommand{\\xx}{\\mathbf{x}}\n\\newcommand{\\yy}{\\mathbf{y}}\n\\newcommand{\\zer}{\\mathbf{0}}\n\\newcommand{\\basis}[2]{\\{\\mathbf{#1}_1,\\mathbf{#1}_2,\\ldots,\\mathbf{#1}_{#2}\\}}\n\\newcommand{\\lt}{<}\n\\newcommand{\\gt}{>}\n\\newcommand{\\amp}{&}\n$"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h6 class=\"heading hide-type\"><span xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"type\">Section<\/span> <span class=\"codenumber\">2.3<\/span> <span class=\"title\">Isomorphisms (a.k.a. invertible linear maps)<\/span><\/h6><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-305\">We ended the last section with an important result. <a href=\"sec-kernel-image.ipynb#ex-dimension-injection-surjection\" class=\"internal\" title=\"Exercise 2.2.8\">Exercise 2.2.8<\/a> showed that existence of an injective linear map $T:V\\to W$ is equivalent to $\\dim V\\leq \\dim W\\text{,}$ and that existence of a surjective linear map is equivalent to $\\dim V\\geq \\dim W\\text{.}$ It's probably not surprising than that existence of a <em class=\"emphasis\">bijective<\/em> linear map $T:V\\to W$ is equivalent to $\\dim V = \\dim W\\text{.}$<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"definition definition-like\" id=\"def-isomorphism\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Definition<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">2.3.1<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-306\">A bijective linear transformation $T:V\\to W$ is called an <dfn class=\"terminology\">isomorphism<\/dfn>. If such a map exists, we say that $V$ and $W$ are <dfn class=\"terminology\">isomorphic<\/dfn>, and write $V\\cong W\\text{.}$<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem theorem-like\" id=\"thm-iso-dimension\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Theorem<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">2.3.2<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-307\">For any finite-dimensional vector spaces $V$ and $W\\text{,}$ $V\\cong W$ if any only if $\\dim V = \\dim W\\text{.}$<\/p><\/article><article class=\"proof\" id=\"proof-14\"><h6 class=\"heading\"><span class=\"type\">Proof<span class=\"period\">.<\/span><\/span><\/h6><p id=\"p-308\">If $T:V\\to W$ is a bijection, then it is both injective and surjective. Since $T$ is injective, $\\dim V\\leq \\dim W\\text{,}$ by <a href=\"sec-kernel-image.ipynb#ex-dimension-injection-surjection\" class=\"internal\" title=\"Exercise 2.2.8\">Exercise 2.2.8<\/a>. By this same exercise,  since $T$ is surjective, we must have $\\dim V\\geq \\dim W\\text{.}$ It follows that $\\dim V=\\dim W\\text{.}$<\/p><p id=\"p-309\">Suppose now that $\\dim V =\\dim W\\text{.}$ Then we can choose bases $\\{\\vv_1,\\ldots, \\vv_n\\}$ of $V\\text{,}$ and $\\{\\ww_1,\\ldots, \\ww_n\\}$ of $W\\text{.}$ <a href=\"sec-lin-tran-intro.ipynb#thm-define-using-basis\" class=\"internal\" title=\"Theorem 2.1.5\">Theorem 2.1.5<\/a> then guarantees the existence of a linear map $T:V\\to W$ such that $T(\\vv_i)=\\ww_i$ for each $i=1,2,\\ldots, n\\text{.}$ Repeating the arguments of <a href=\"sec-kernel-image.ipynb#ex-dimension-injection-surjection\" class=\"internal\" title=\"Exercise 2.2.8\">Exercise 2.2.8<\/a> shows that $T$ is a bijection.<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-310\">Note that buried in the theorem above is the following useful fact: <em class=\"emphasis\">an isomorphism $T:V\\to W$ takes any basis of $V$ to a basis of $W$<\/em>. Another remarkable result of the above theorem is that <em class=\"emphasis\">any two vector spaces of the same dimension are isomorphic<\/em>! In particular, we have the following theorem.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem theorem-like\" id=\"thm-iso-rn\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Theorem<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">2.3.3<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-311\">If $\\dim V=n\\text{,}$ then $V\\cong \\R^n\\text{.}$<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-312\">This theorem is a direct consequence of <a href=\"sec-isomorphism.ipynb#thm-iso-dimension\" class=\"internal\" title=\"Theorem 2.3.2\">Theorem 2.3.2<\/a>. But it's useful to understand how it works in practice.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"definition definition-like\" id=\"def-coefficient-iso\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Definition<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">2.3.4<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-313\">Let $V$ be a finite-dimensional vector space, and let $B=\\{\\mathbf{e}_1,\\ldots, \\mathbf{e}_n\\}$ be a basis for $V\\text{.}$ The <dfn class=\"terminology\">coefficient isomorphism<\/dfn> associated to $B$ is the map $C_B:V\\to \\R^n$ defined by<\/p><div class=\"displaymath\">\n\\begin{equation*}\nC_B(c_1\\mathbf{e}_1+c_2\\mathbf{e}_2+\\cdots +c_n\\mathbf{e}_n)=\\bbm c_1\\\\c_2\\\\\\vdots \\\\c_n\\ebm\\text{.}\n\\end{equation*}\n<\/div><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-314\">Note that this is a well-defined map since every vector in $V$ can be written uniquely in terms of the basis $B\\text{.}$<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-315\">The coefficient isomorphism is especially useful when we want to analyze a linear map computationally. Suppose we're given $T:V\\to W$ where $V, W$ are finite-dimensional. Let us choose bases $B=\\{\\vv_1,\\ldots, \\vv_n\\}$ of $V$ and $B' = \\{\\ww_1,\\ldots, \\ww_m\\}$ of $W\\text{.}$ The choice of these two bases determines scalars $a_{ij}, 1\\leq i\\leq n, 1\\leq j\\leq m\\text{,}$ such that<\/p><div xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"displaymath\">\n\\begin{equation*}\nT(\\vv_j) = a_{1j}\\ww_1+a_{2j}\\ww_2+\\cdots + a_{mj}\\ww_j,\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">for each $i=1,2,\\ldots, n\\text{.}$ The resulting matrix $A=[a_{ij}]$ defines a matrix transformation $T_A:\\R^n\\to \\R^m$ such that<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT_A\\circ C_B = C_{B'}\\circ T\\text{.}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">The relationship among the four maps used here is best captured by the following “commutative diagram”:<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><figure class=\"figure figure-like\" id=\"fig_transformation_matrix\"><div xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"image-box\" style=\"width: 35%; margin-left: 32.5%; margin-right: 32.5%;\"><img src=\"images\/img_trans_matrix.svg\" width=\"35%\" alt=\"\" \/><\/div><figcaption><span class=\"type\">Figure<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">2.3.5<span class=\"period\">.<\/span><\/span><span class=\"space\"> <\/span>Defining the matrix of a linear map with respect to choices of basis.<\/figcaption><\/figure><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-316\">With this connection between linear maps (in general) and matrices, it can be worthwhile to pause and consider invertibility in the context of matrices. Recall that an $n\\times n$ matrix $A$ is <em class=\"emphasis\">invertible<\/em> if there exists a matrix $A^{-1}$ such that $AA^{-1}=I_n$ and $A^{-1}A=I_n\\text{.}$<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" id=\"p-317\">The same definition can be made for linear maps. We've defined what it means for a map $T:V\\to W$ to be invertible as a <em class=\"emphasis\">function<\/em>. In particular, we relied on the fact that any bijection has an inverse.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-318\">First, a note on notation. Given linear maps $U\\xrightarrow{T} V\\xrightarrow{S} W\\text{,}$ we typically write the composition $S\\circ T:U\\to W$ as a “product” $ST\\text{.}$ The reason for this is again to mimic the case of matrices. Let $A$ be an $m\\times n$ matrix, and let $B$ be an $n\\times k$ matrix. Then we have linear maps<\/p><div xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"displaymath\">\n\\begin{equation*}\n\\R^k \\xrightarrow{T_B} \\R^n\\xrightarrow{T_A} \\R^m\\text{,}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">and the composition $T_A\\circ T_B:\\R^k\\to \\R^m$ satisfies<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT_A\\circ T_B(\\xx) = T_A(T_B(\\xx)) = T_A(B\\xx)=A(B\\xx)=(AB)\\xx=T_{AB}(\\xx)\\text{.}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">Note that the rules given in elementary linear algebra, for the relative sizes of matrices that can be multiplied, are simply a manifestation of the fact that to compose functions, the range of the first must be contained in the domain of the second.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise exercise-like\" id=\"exercise-23\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Exercise<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">2.3.6<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-319\">Show that the composition of two linear maps is again a linear map.<\/p><div class=\"solutions\"><a data-knowl=\"\" class=\"id-ref solution-knowl original\" data-refid=\"hk-solution-19\" id=\"solution-19\"><span class=\"type\">Solution<\/span><\/a><div class=\"hidden-content tex2jax_ignore\" id=\"hk-solution-19\"><div class=\"solution solution-like\"><p id=\"p-320\">Suppose we have linear maps $U\\xrightarrow{T} V\\xrightarrow{S} W\\text{,}$ and let $\\uu_1,\\uu_2\\in U\\text{.}$ Then<\/p><div class=\"displaymath\">\n\\begin{align*}\nST(\\uu_1+\\uu_2) \\amp = S(T(\\uu_1+\\uu_2)) \\\\\n\\amp = S(T(\\uu_1)+T(\\uu_2))\\\\\n\\amp = S(T(\\uu_1))+S(T(\\uu_2)) \\\\\n\\amp = ST(\\uu_1)+ST(\\uu_2)\\text{,}\n\\end{align*}\n<\/div><p data-braille=\"continuation\">and for any scalar $c\\text{,}$<\/p><div class=\"displaymath\">\n\\begin{equation*}\nST(c\\uu_1) = S(T(c\\uu_1))=S(cT(\\uu_1)) = cS(T(\\uu_1))=c(ST(\\uu_1))\\text{.}\n\\end{equation*}\n<\/div><\/div><\/div><\/div><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-321\">Moreover, <a href=\"sec-isomorphism.ipynb#thm-iso-dimension\" class=\"internal\" title=\"Theorem 2.3.2\">Theorem 2.3.2<\/a> tells us why we can only consider invertibility for square matrices: we know that invertible linear maps are only defined between spaces of equal dimension. In analogy with matrices, some texts will define a linear map $T:V\\to W$ to be invertible if there exists a linear map $S:W\\to V$ such that<\/p><div xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"displaymath\">\n\\begin{equation*}\nST = 1_V \\quad \\text{ and } \\quad TS = 1_W\\text{.}\n\\end{equation*}\n<\/div><p data-braille=\"continuation\">From this definition, one can show that $S$ and $T$ must be bijections, and of course, if $T$ is a bijection (as in our definition) then we know it has an inverse. What remains to be seen is that this inverse is also a linear map.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise exercise-like\" id=\"exercise-24\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Exercise<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">2.3.7<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-322\">Let $T:V\\to W$ be a bijective linear transformation. Show that $T^{-1}:W\\to V$ is a linear transformation.<\/p><div class=\"solutions\"><a data-knowl=\"\" class=\"id-ref solution-knowl original\" data-refid=\"hk-solution-20\" id=\"solution-20\"><span class=\"type\">Solution<\/span><\/a><div class=\"hidden-content tex2jax_ignore\" id=\"hk-solution-20\"><div class=\"solution solution-like\"><p id=\"p-323\">Let $\\ww_1,\\ww_2\\in W\\text{.}$ Then there exist $\\vv_1,\\vv_2\\in V$  with $\\ww_1=T(\\vv_1), \\ww_2=T(\\vv_2)\\text{.}$ We then have<\/p><div class=\"displaymath\">\n\\begin{align*}\nT^{-1}(\\ww_1+\\ww_2) \\amp = T^{-1}(T(\\vv_1)+T(\\vv_2)) \\\\\n\\amp = T^{-1}(T(\\vv_1+\\vv_2))\\\\\n\\amp = \\vv_1+\\vv_2\\\\\n\\amp = T^{-1}(\\ww_1)+T^{-1}(\\ww_2)\\text{.}\n\\end{align*}\n<\/div><p data-braille=\"continuation\">For any scalar $c\\text{,}$ we similarly have<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT^{-1}(c\\ww_1) = T^{-1}(cT(\\vv_1))=T^{-1}(T(c\\vv_1)) = c\\vv_1 = cT^{-1}(\\ww_1)\\text{.}\n\\end{equation*}\n<\/div><\/div><\/div><\/div><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise exercise-like\" id=\"exercise-25\"><h6 xmlns:svg=\"http:\/\/www.w3.org\/2000\/svg\" class=\"heading\"><span class=\"type\">Exercise<\/span><span class=\"space\"> <\/span><span class=\"codenumber\">2.3.8<\/span><span class=\"period\">.<\/span><\/h6><p id=\"p-324\">Show that if $ST=1_V\\text{,}$ then $S$ is surjective and $T$ is injective. Conclude that if $ST=1_V$ and $TS=1_w\\text{,}$ then $S$ and $T$ are both bijections.<\/p><div class=\"solutions\"><a data-knowl=\"\" class=\"id-ref hint-knowl original\" data-refid=\"hk-hint-1\" id=\"hint-1\"><span class=\"type\">Hint<\/span><\/a><div class=\"hidden-content tex2jax_ignore\" id=\"hk-hint-1\"><div class=\"hint solution-like\"><p id=\"p-325\">This is really a Math 2000 problem.<\/p><\/div><\/div><\/div><\/article><\/div>"]}
],
"nbformat": 4, "nbformat_minor": 0, "metadata": {"kernelspec": {"display_name": "", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}, "name": "sec-isomorphism.ipynb"}
}