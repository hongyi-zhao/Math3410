{
"cells": [
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":["%%html\n<link href=\"https:\/\/pretextbook.org\/beta\/mathbook-content.css\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/aimath.org\/mathbook\/mathbook-add-on.css\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/fonts.googleapis.com\/css?family=Open+Sans:400,400italic,600,600italic\" rel=\"stylesheet\" type=\"text\/css\" \/>\n<link href=\"https:\/\/fonts.googleapis.com\/css?family=Inconsolata:400,700&subset=latin,latin-ext\" rel=\"stylesheet\" type=\"text\/css\" \/><!-- Hide this cell. -->\n<script>\nvar cell = $(\".container .cell\").eq(0), ia = cell.find(\".input_area\")\nif (cell.find(\".toggle-button\").length == 0) {\nia.after(\n    $('<button class=\"toggle-button\">Toggle hidden code<\/button>').click(\n        function (){ ia.toggle() }\n        )\n    )\nia.hide()\n}\n<\/script>\n"], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["**Important:** to view this notebook properly you will need to execute the cell above, which assumes you have an Internet connection.  It should already be selected, or place your cursor anywhere above to select.  Then press the \"Run\" button in the menu bar above (the right-pointing arrowhead), or press Shift-Enter on your keyboard."]},
{"cell_type":"markdown", "metadata":{}, "source":["$\\newcommand{\\spn}{\\operatorname{span}}\n\\newcommand{\\bbm}{\\begin{bmatrix}}\n\\newcommand{\\ebm}{\\end{bmatrix}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\Img}{\\operatorname{im}}\n\\newcommand{\\nll}{\\operatorname{null}}\n\\newcommand{\\csp}{\\operatorname{col}}\n\\newcommand{\\rank}{\\operatorname{rank}}\n\\newcommand{\\lt}{<}\n\\newcommand{\\gt}{>}\n\\newcommand{\\amp}{&}\n$"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h6 class=\"heading hide-type\"><span class=\"type\">Section<\/span> <span class=\"codenumber\">3.1<\/span> <span class=\"title\">Definition and examples<\/span><\/h6><a href=\"sec-lin-tran-intro.ipynb\" class=\"permalink\">¶<\/a><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-149\">Let $V$ and $W$ be vector spaces. At their most basic, all vector spaces are sets. Given any two sets, we can consider functions from one to the other. The functions of interest in linear algebra are those that respect the vector space structure of the sets.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"definition-like\" id=\"def-lin-trans\"><h6 class=\"heading\"><span class=\"type\">Definition<\/span> <span class=\"codenumber\">3.1.1<\/span>.<\/h6><p id=\"p-150\">Let $V$ and $W$ be vector spaces. A function $T:V\\to W$ is called a <dfn class=\"terminology\">linear transformation<\/dfn> if:<\/p><ol class=\"decimal\"><li id=\"li-23\"><p id=\"p-151\">For all $\\vec{v}_1,\\vec{v}_2\\in V\\text{,}$ $T(\\vec{v}_1+\\vec{v}_2)=T(\\vec{v}_1)+T(\\vec{v}_2)\\text{.}$<\/p><\/li><li id=\"li-24\"><p id=\"p-152\">For all $\\vec{v}\\in V$ and scalars $c\\text{,}$ $T(c\\vec{v})=cT(\\vec{v})\\text{.}$<\/p><\/li><\/ol><p>We often use the term <dfn class=\"terminology\">linear operator<\/dfn> to refer to a linear transformation $T:V\\to V$ from a vector space to itself.<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-153\">Note on notation: it is common useage to drop the usual parentheses of function notation when working with linear transformations, as long as this does not cause confusion. That is, one might write $T\\vec{v}$ instead of $T(\\vec{v})\\text{,}$ but one should never write $T\\vec{v}+\\vec{w}$ in place of $T(\\vec{v}+\\vec{w})\\text{,}$ for the same reason that one should never write $2x+y$ in place of $2(x+y)\\text{.}$ Mathematicians often think of linear transformations in terms of matrix multiplication, which probably explains this notation to some extent.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-154\">The properties of a linear transformation tell us that a linear map $T$ <em class=\"emphasis\">preserves<\/em> the operations of addition and scalar multiplication. (When the domain and codomain are different vector spaces, we might say that $T$ <em class=\"emphasis\">intertwines<\/em> the operations of the two vector spaces.) In particular, any linear transformation $T$ must preserve the zero vector, and respect linear combinations.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem-like\" id=\"thm-lt-props\"><h6 class=\"heading\"><span class=\"type\">Theorem<\/span> <span class=\"codenumber\">3.1.2<\/span>.<\/h6><p id=\"p-155\">Let $T:V\\to W$ be a linear transformation. Then<\/p><ol class=\"decimal\"><li id=\"li-25\"><p id=\"p-156\">$T(\\vec{0}_V) = \\vec{0}_W\\text{,}$ and<\/p><\/li><li id=\"li-26\"><p id=\"p-157\">For any scalars $c_1,\\ldots, c_n$ and vectors $\\vec{v}_1,\\ldots, \\vec{v}_n\\in V\\text{,}$<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT(c_1\\vec{v}_1+c_2\\vec{v}_2+\\cdots + c_n\\vec{v}_n) = c_1T(\\vec{v}_1)+c_2T(\\vec{v}_2)+\\cdots + c_nT(\\vec{v}_n)\\text{.}\n\\end{equation*}\n<\/div><\/li><\/ol><\/article><article class=\"proof\" id=\"proof-7\"><h6 class=\"heading\"><span class=\"type\">Proof.<\/span><\/h6><ol id=\"p-158\" class=\"decimal\"><li id=\"li-27\"><p id=\"p-159\">Since $\\vec{0}_V+\\vec{0}_V = \\vec{0}_V\\text{,}$ we have<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT(\\vec{0}_V) = T(\\vec{0}_V+\\vec{0}_V) = T(\\vec{0}_V)+T(\\vec{0}_V)\\text{.}\n\\end{equation*}\n<\/div><p>Adding $-T(\\vec{0}_V)$ to both sides of the above gives us $\\vec{0}_W = T(\\vec{0}_V)\\text{.}$<\/p><\/li><li id=\"li-28\"><p id=\"p-160\">The addition property of a linear transformation can be extended to sums of three or more vectors using associativity. Therefore, we have<\/p><div class=\"displaymath\">\n\\begin{align*}\nT(c_1\\vec{v}_1+\\cdots + c_n\\vec{v}_n) \\amp = T(c_1\\vec{v}_1)+ \\cdots T(c_n\\vec{v}_n)\\\\\n\\amp = c_1T(\\vec{v}_1)+\\cdots +c_nT(\\vec{v}_n)\\text{,}\n\\end{align*}\n<\/div><p>where the second line follows from the scalar multiplication property.<\/p><\/li><\/ol><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"ex-matrix-trans\"><h6 class=\"heading\"><span class=\"type\">Example<\/span> <span class=\"codenumber\">3.1.3<\/span>.<\/h6><p id=\"p-161\">Let $V=\\R^n$ and let $W=\\R^m\\text{.}$ For any $m\\times n$ matrix $A\\text{,}$ the map $T_A:\\R^n\\to \\R^m$ defined by<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT_A(\\vec{x}) = A\\vec{x}\n\\end{equation*}\n<\/div><p>is a linear transformation. (This follows immediately from properties of matrix multiplication.)<\/p><p id=\"p-162\">Let $B = \\{\\vec{e}_1,\\ldots, \\vec{e}_n\\}$ denote the standard basis of $\\R^n\\text{.}$ Recall that $A\\vec{e}_i$ is equal to the $i$th column of $A\\text{.}$ Thus, if we know the value of a linear transformation $T:\\R^n\\to \\R^m$ on each basis vector, we can immediately determine the matrix $A$ such that $T=T_A\\text{:}$<\/p><div class=\"displaymath\">\n\\begin{equation*}\nA = \\bbm T(\\vec{e}_1) \\amp T(\\vec{e}_2) \\amp \\cdots \\amp T(\\vec{e}_n)\\ebm\\text{.}\n\\end{equation*}\n<\/div><p>This is true because $T$ and $T_A$ agree on the standard basis: for each $i=1,2,\\ldots, n\\text{,}$<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT_A(\\vec{e_i}) = A\\vec{e_i} = T(\\vec{e}_i)\\text{.}\n\\end{equation*}\n<\/div><p>Moreover, if two linear transformations agree on a basis, they must be equal. Given any $\\vec{x}\\in \\R^n\\text{,}$ we can write $\\vec{x}$ uniquely as a linear combination<\/p><div class=\"displaymath\">\n\\begin{equation*}\n\\vec{x}=c_1\\vec{e}_1+c_2\\vec{e}_2+\\cdots + c_n\\vec{e}_n.\n\\end{equation*}\n<\/div><p>If $T(\\vec{e}_i)=T_A(\\vec{e}_i)$ for each $i\\text{,}$ then by <a href=\"sec-lin-tran-intro.ipynb#thm-lt-props\" class=\"internal\" title=\"Theorem 3.1.2\">Theorem 3.1.2<\/a> we have<\/p><div class=\"displaymath\">\n\\begin{align*}\nT(\\vec{x}) \\amp = T(c_1\\vec{e}_1+c_2\\vec{e}_2+\\cdots + c_n\\vec{e}_n) \\\\\n\\amp = c_1T(\\vec{e}_1)+c_2T(\\vec{e}_2)+\\cdots + c_nT(\\vec{e}_n)\\\\\n\\amp = c_1T_A(\\vec{e}_1)+c_2T_A(\\vec{e}_2)+\\cdots + c_nT_A(\\vec{e}_n)\\\\\n\\amp = T_A(c_1\\vec{e}_1+c_2\\vec{e}_2+\\cdots + c_n\\vec{e}_n) \\\\\n\\amp = T_A(\\vec{x})\\text{.}\n\\end{align*}\n<\/div><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-163\">Let's look at some other examples of linear transformations.<\/p><ul class=\"disc\"><li id=\"li-29\"><p id=\"p-164\">For any vector spaces $V,W$ we can define the <dfn class=\"terminology\">zero transformation<\/dfn> $0:V\\to W$ by $0(\\vec{v})=\\vec{0}$ for all $\\vec{v}\\in V\\text{.}$<\/p><\/li><li id=\"li-30\"><p id=\"p-165\">On any vector space $V$ we have the <dfn class=\"terminology\">identity transformation<\/dfn> $1_V:V\\to V$ defined by $1_V(\\vec{v})=\\vec{v}$ for all $\\vec{v}\\in V\\text{.}$<\/p><\/li><li id=\"li-31\"><p id=\"p-166\">Let $V = F[a,b]$ be the space of all functions $f:[a,b]\\to \\R\\text{.}$ For any $c\\in [a,b]$ we have the <dfn class=\"terminology\">evaluation map<\/dfn> $E_a: V\\to \\R$ defined by $E_a(f) = f(a)\\text{.}$<\/p><p id=\"p-167\">To see that this is linear, note that $E_a(0)=\\mathbf{0}(a)=0\\text{,}$ where $mathbf{0}$ denotes the zero function; for any $f,g\\in V\\text{,}$<\/p><div class=\"displaymath\">\n\\begin{equation*}\nE_a(f+g)=(f+g)(a)=f(a)+g(a)=E_a(f)+E_a(g)\\text{,}\n\\end{equation*}\n<\/div><p>and for any scalar $c\\in \\R\\text{,}$<\/p><div class=\"displaymath\">\n\\begin{equation*}\nE_a(cf) = (cf)(a) = c(f(a))=cE_a(f)\\text{.}\n\\end{equation*}\n<\/div><p id=\"p-168\">Note that the evaluation map can similarly be defined as a linear transformation on any vector space of polynomials.<\/p><\/li><li id=\"li-32\"><p id=\"p-169\">On the vector space $C[a,b]$ of all <em class=\"emphasis\">continuous<\/em> functions on $[a,b]\\text{,}$ we have the integration map $I:C[a,b]\\to \\R$ defined by $I(f)=\\int_a^b f(x)\\,dx\\text{.}$ The fact that this is a linear map follows from properties of integrals proved in a calculus class.<\/p><\/li><li id=\"li-33\"><p id=\"p-170\">On the vector space $C^1(a,b)$ of continuously differentiable functions on $(a,b)\\text{,}$ we have the differentiation map $D: C^1(a,b)\\to C(a,b)$ defined by $D(f) = f'\\text{.}$ Again, linearity follows from properties of the derivative.<\/p><\/li><li id=\"li-34\"><p id=\"p-171\">Let $\\R^\\infty$ denote the set of sequences $(a_1,a_2,a_3,\\ldots)$ of real numbers, with term-by-term addition and scalar multiplication. The shift operators<\/p><div class=\"displaymath\">\n\\begin{align*}\nS_L(a_1,a_2,a_3,\\ldots)  \\amp = (a_2,a_3,a_4,\\ldots) \\\\\nS_R(a_1,a_2,a_3,\\ldots) \\amp = (0,a_1,a_2,\\ldots)\n\\end{align*}\n<\/div><p>are both linear.<\/p><\/li><li id=\"li-35\"><p id=\"p-172\">On the space $M_{mn}(\\R)$ of $m\\times n$ matrices, the trace defines a linear map $\\operatorname{tr}:M_{mn}(\\R)\\to \\R\\text{,}$ and the transpose defines a linear map $T:M_{mn}(\\R)\\to M_{nm}(\\R)\\text{.}$ The determinant and inverse operations on $M_{nn}$ are <em class=\"emphasis\">not<\/em> linear.<\/p><\/li><\/ul><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-173\">For finite-dimensional vector spaces, it is often convenient to work in terms of a basis. The properties of a linear transformation tell us that we can completely define any linear transformation by giving its values on a basis. In fact, it's enough to know the value of a transformation on a spanning set. The argument given in <a href=\"sec-lin-tran-intro.ipynb#ex-matrix-trans\" class=\"internal\" title=\"Example 3.1.3\">Example 3.1.3<\/a> can be applied to any linear transformation, to obtain the following result.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem-like\" id=\"thm-agree-span\"><h6 class=\"heading\"><span class=\"type\">Theorem<\/span> <span class=\"codenumber\">3.1.4<\/span>.<\/h6><p id=\"p-174\">Let $T:V\\to W$ and $S:V\\to W$ be two linear transformations. If $V = \\spn\\{\\vec{v}_1,\\ldots, \\vec{v}_n$ and $T(\\vec{v}_i)=S(\\vec{v}_i)$ for each $i=1,2,\\ldots, n\\text{,}$ then $T=S\\text{.}$<\/p><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-175\">If the above spanning set is not also independent, then one might be concerned about the fact that there will be more than one way to express a vector as linear combination of vectors in that set. If we define $T$ by giving its values on a spanning set, will it be well-defined? Suppose that we have scalars $a_1,\\ldots, a_n, b_1,\\ldots, b_n$ such that<\/p><div class=\"displaymath\">\n\\begin{align*}\n\\vec{v} \\amp a_1\\vec{v_1}+\\cdots + a_n\\vec{v}_n\\\\\n\\amp b_1\\vec{v}_1+\\cdots + b_n\\vec{v}_n\n\\end{align*}\n<\/div><p>We then have<\/p><div class=\"displaymath\">\n\\begin{align*}\na_1T(\\vec{v}_1)+\\cdots + a_nT(\\vec{v}_n) \\amp T(a_1\\vec{v}_1+\\cdots + a_n\\vec{v}_n) \\\\\n\\amp T(b_1\\vec{v}_1+\\cdots +b_n\\vec{v}_n)\\\\\n\\amp b_1T(\\vec{v}_1)+\\cdots +b_nT(\\vec{v}_n)\\text{.}\n\\end{align*}\n<\/div><p>The next theorem seems like an obvious consequence of the above, and indeed, one might wonder where the assumption of a basis is needed. The distinction here is that the vectors $\\vec{w}_1,\\ldots, \\vec{w}_n\\in W$ are chosen in advance, and then we set $T(vec{b}_i)=\\vec{w}_i\\text{,}$ rather than simply defining each $\\vec{w}_i$ as $T(\\vec{b}_i)\\text{.}$<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem-like\" id=\"thm-define-using-basis\"><h6 class=\"heading\"><span class=\"type\">Theorem<\/span> <span class=\"codenumber\">3.1.5<\/span>.<\/h6><p id=\"p-176\">Let $V,W$ be vector spaces. Let $B=\\{\\vec{b}_1,\\ldots, \\vec{b}_n\\}$ be a basis of $V\\text{,}$ and let $\\vec{w}_1,\\ldots, \\vec{w}_n$ be any vectors in $W\\text{.}$ (These vectors need not be distinct.) Then there exists a unique linear transformation $T:V\\to W$ such that $T(\\vec{b}_i)=\\vec{w}_i$ for each $i=1,2,\\ldots, n\\text{;}$ indeed, we can define $T$ as follows: given $\\vec{v}\\in V\\text{,}$ write $\\vec{v}=c_1\\vec{v}_1+\\cdots +c_n\\vec{v}_n\\text{.}$ Then<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT(\\vec{v})=T(c_1\\vec{v}_1+\\cdots + c_n\\vec{v}_n) = c_1\\vec{w}_1+\\cdots +c_n\\vec{v}_n\\text{.}\n\\end{equation*}\n<\/div><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-177\">With the basic theory out of the way, let's look at a few basic examples.<\/p><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise-like\" id=\"exercise-16\"><h6 class=\"heading\"><span class=\"type\">Exercise<\/span> <span class=\"codenumber\">3.1.6<\/span>.<\/h6><p id=\"p-178\">Suppose $T:\\R^2\\to \\R^2$ is a linear transformation. If $T\\bbm 1\\\\0\\ebm = \\bbm 3\\\\-4\\ebm$ and $T\\bbm 0\\\\1\\ebm =\\bbm 5\\\\2\\ebm\\text{,}$ find $T=\\bbm -2\\\\4\\ebm\\text{.}$<\/p><div class=\"solutions\"><a data-knowl=\"\" class=\"id-ref\" data-refid=\"hk-solution-4\" id=\"solution-4\"><span class=\"type\">Solution<\/span><\/a><div id=\"hk-solution-4\" class=\"hidden-content tex2jax_ignore\"><div class=\"solution\"><p id=\"p-179\">Since we know the value of $T$ on the standard basis, we can use properties of linear transformations to immediately obtain the answer:<\/p><div class=\"displaymath\">\n\\begin{align*}\nT\\bbm -2\\\\4\\ebm \\amp= T\\left(-2\\bbm 1\\\\0\\ebm +4\\bbm 0\\\\1\\ebm\\right)\\\\\n\\amp = -2T\\bbm1\\\\0\\ebm+4T\\bbm 0\\\\1\\ebm\\\\\n\\amp = -2\\bbm 3\\\\-4\\ebm +4\\bbm 5\\\\2\\ebm\\\\\n\\amp = \\bbm 14\\\\16\\ebm\\text{.}\n\\end{align*}\n<\/div><\/div><\/div><\/div><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise-like\" id=\"exercise-17\"><h6 class=\"heading\"><span class=\"type\">Exercise<\/span> <span class=\"codenumber\">3.1.7<\/span>.<\/h6><p id=\"p-180\">Suppose $T:\\R^2\\to \\R^2$ is a linear tranasformation. Given that $T\\bbm 3\\\\1\\ebm = \\bbm 1\\\\4\\ebm$ and $T\\bbm 2\\\\-5\\ebm = \\bbm 2\\\\-1\\ebm\\text{,}$ find $T\\bbm 4\\\\3\\ebm\\text{.}$<\/p><div class=\"solutions\"><a data-knowl=\"\" class=\"id-ref\" data-refid=\"hk-solution-5\" id=\"solution-5\"><span class=\"type\">Solution<\/span><\/a><div id=\"hk-solution-5\" class=\"hidden-content tex2jax_ignore\"><div class=\"solution\"><p id=\"p-181\">At first, this example looks the same as the one above, and to some extent, it is. The difference is that this time, we're given the values of $T$ on a basis that is not the standard one. This means we first have to do some work to determine how to write the given vector in terms of the given basis.<\/p><p id=\"p-182\">Suppose we have $a\\bbm 3\\\\1\\ebm+b\\bbm 2\\\\-5\\ebm = \\bbm 4\\\\3\\ebm$ for scalars $a,b\\text{.}$ This is equivalent to the matrix equation<\/p><div class=\"displaymath\">\n\\begin{equation*}\n\\bbm 3\\amp 2\\\\1\\amp -5\\ebm\\bbm a\\\\b\\ebm = \\bbm 4\\\\3\\ebm.\n\\end{equation*}\n<\/div><p>Solving (perhaps using the code cell below), we get $a=\\frac{26}{17}, b = -\\frac{5}{17}\\text{.}$ Therefore,<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT\\bbm 3\\\\4\\ebm = \\frac{26}{17}\\bbm 1\\\\4\\ebm -\\frac{5}{17}\\bbm 2\\\\-1\\ebm = \\bbm 16\/17\\\\109\/17\\ebm\\text{.}\n\\end{equation*}\n<\/div><\/div><\/div><\/div><\/article><\/div>"]},
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":["from sympy import *\ninit_printing()\nA = Matrix(2,2,[3,2,1,-5])\nB = Matrix(2,1,[4,3])\n(A**-1)*B"], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise-like\" id=\"exercise-18\"><h6 class=\"heading\"><span class=\"type\">Exercise<\/span> <span class=\"codenumber\">3.1.8<\/span>.<\/h6><p id=\"p-183\">Suppose $T:P_2(\\R)\\to \\R$ is defined by<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT(x+2)=1, T(1)=5, T(x^2+x)=0.\n\\end{equation*}\n<\/div><p>Find $T(2-x+3x^2)\\text{.}$<\/p><div class=\"solutions\"><a data-knowl=\"\" class=\"id-ref\" data-refid=\"hk-solution-6\" id=\"solution-6\"><span class=\"type\">Solution<\/span><\/a><div id=\"hk-solution-6\" class=\"hidden-content tex2jax_ignore\"><div class=\"solution\"><p id=\"p-184\">We need to find scalars $a,b,c$ such that<\/p><div class=\"displaymath\">\n\\begin{equation*}\n2-x+3x^2 = a(x+2)+b(1)+c(x^2+x)\\text{.}\n\\end{equation*}\n<\/div><p>We could set up a system and solve, but this time it's easy enough to just work our way through. We must have $c=3\\text{,}$ to get the correct coefficient for $x^2\\text{.}$ This gives<\/p><div class=\"displaymath\">\n\\begin{equation*}\n2-x+3x^2=a(x+2)+b(1)+3x^2+3x\\text{.}\n\\end{equation*}\n<\/div><p>Now, we have to have $3x+ax=-x\\text{,}$ so $a=-4\\text{.}$ Putting this in, we get<\/p><div class=\"displaymath\">\n\\begin{equation*}\n2-x+3x^2=-4x-8+b+3x^2+3x\\text{.}\n\\end{equation*}\n<\/div><p>Simiplifying this leaves us with $b=10\\text{.}$ Finally, we find:<\/p><div class=\"displaymath\">\n\\begin{align*}\nT(2-x+3x^2) \\amp = T(-4(x+2)+10(1)+3(x^2+x)) \\\\\n\\amp = -4T(x+2)+10T(1)+3T(x^2+x)\\\\\n\\amp = -4(1)+10(5)+3(0) = 46\\text{.}\n\\end{align*}\n<\/div><\/div><\/div><\/div><\/article><\/div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"exercise-like\" id=\"exercise-19\"><h6 class=\"heading\"><span class=\"type\">Exercise<\/span> <span class=\"codenumber\">3.1.9<\/span>.<\/h6><p id=\"p-185\">Find a linear transformation $T:\\R^2\\to \\R^3$ such that<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT(1,2)=(1,1,0) \\quad \\text{ and } \\quad T(-1,1) = (0,2,-1)\\text{.}\n\\end{equation*}\n<\/div><p>Then, determine the value of $T(3,2)\\text{.}$<\/p><div class=\"solutions\"><a data-knowl=\"\" class=\"id-ref\" data-refid=\"hk-solution-7\" id=\"solution-7\"><span class=\"type\">Solution<\/span><\/a><div id=\"hk-solution-7\" class=\"hidden-content tex2jax_ignore\"><div class=\"solution\"><p id=\"p-186\">Since $\\{(1,2),(-1,1)\\}$ forms a basis of $\\R^2$ (the vectors are not parallel and there are two of them), it suffices to determine how to write a general vector in terms of this basis. suppose<\/p><div class=\"displaymath\">\n\\begin{equation*}\nx(1,2)+y(-1,1)=(a,b)\n\\end{equation*}\n<\/div><p>for a general element $(a,b)\\in \\R^2\\text{.}$ This is equivalent to the matrix equation $\\bbm 1\\amp -1\\\\2\\amp 1\\ebm\\bbm x\\\\y\\ebm = \\bbm a\\\\b\\ebm\\text{.}$ We find:<\/p><div class=\"displaymath\">\n\\begin{equation*}\n(a,b) = \\frac13(a+b)(1,2)+\\frac13(-2a+b)(-1,1).\n\\end{equation*}\n<\/div><p>Thus,<\/p><div class=\"displaymath\">\n\\begin{align*}\nT(a,b) \\amp = \\frac13(a+b)T(1,2)+\\frac13(-2a+b)T(-1,1) \\\\\n\\amp = \\frac13(a+b)(1,1,0)+\\frac13(-2a+b)(0,2,-1)\\\\\n\\amp = \\left(\\frac{a+b}{3}, -a+b, \\frac{2a-b}{3}\\right)\\text{.}\n\\end{align*}\n<\/div><p>Therefore,<\/p><div class=\"displaymath\">\n\\begin{equation*}\nT(3,2) = \\left(\\frac53, -1, \\frac43\\right)\\text{.}\n\\end{equation*}\n<\/div><\/div><\/div><\/div><\/article><\/div>"]},
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":["a, b = symbols('a b', real = True, constant = True)\nA = Matrix(2,2,[1,-1,2,1])\nB = Matrix(2,1,[a,b])\n(A**-1)*B"], "outputs":[]}
],
"nbformat": 4, "nbformat_minor": 0, "metadata": {"kernelspec": {"display_name": "", "name": "sagemath"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}, "name": "sec-lin-tran-intro.ipynb"}
}